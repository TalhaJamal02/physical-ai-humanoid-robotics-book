---
sidebar_position: 1
---

# Vision-Language-Action (VLA) Concepts

This chapter introduces the core concepts of Vision-Language-Action (VLA) systems.

## What Are VLA Systems?

VLA systems enable robots to understand and execute tasks using both visual perception and natural language instructions.  
They bridge the gap between high-level human commands and low-level robot control.

## Key Components

- **Vision Models**: Process camera feeds to understand the environment, e.g., object detection, segmentation, and pose estimation.  
- **Language Models**: Interpret natural language instructions and convert them into robot-understandable commands.  
- **Grounding**: Connect symbolic representations from language to real-world perceptions from vision.  
- **Action Generation**: Translate grounded understanding into sequences of robot actions.